# REVIEW 稿件

## 1. 技术栈

### 1.1 C++

- C与C++区别
  - 面向对象（封装、继承、多态、抽象） 
  - 函数重载
  - 引用/指针
  - namespace
- new/delete malloc/free
- 深拷贝和零拷贝
  - 深拷贝生成完全一样的新对象
  - 零拷贝绕过cpu，通过内存映射、dma等方式
    - 如Linux的sendfile，java的FileChannel.transferTo
- vector - 动态数组容器
  - 底层实现连续内存空间和动态扩容，初始化为空
  - 扩容机制，分配两倍内存量

### 1.2 Python

- 动态类型
  - 变量无需声明类型，运行时确定类型
- 列表/元组
  - 列表可变，元组不可变（增删改）
- 垃圾回收
  - 基于引用计数
  - 辅助循环垃圾回收器
- 生成器of迭代器
  - 生成器用惰性生成值（不会一次生成所有值）节省内存
  - 迭代器根据是否存在数据（如列表），如果没有会使用生成器
  - 生成器自动迭代，迭代器需要定义next
- GIL锁
  - CPU密集型任务性能差
  - 互斥锁，同一时间只允许一个线程执行python字节码
  - python使用引用计数管理内存，多线程同时修改引用计数器会导致内存错误，从而使大量底层库无序处理线程安全问题
    - java使用追踪的垃圾回收
    - golang使用并发标记清楚
    - C++使用手动管理+智能指针
      - 资源获取即初始化（RAII）的策略，防止内存泄漏/指针悬空

### 1.3 Java

- HashMap 数组+链表/红黑树 （48 16）
- HashSet/TreeSet
  - HashSet基于HashMap，无序
  - TreeSet基于红黑树，有序
- 线程 - 继承Thread类，实现Runnable和Callable
  - CAS （compare and swap）（自旋+CAS实现无锁）
    - CAS本质是无锁，原子操作，不会造成线程切换
  - 锁升级
    - 无锁
    - 偏向锁 - 标记由单个线程持有避免CAS
    - 轻量级锁 - 通过自旋获得锁
    - 重量级锁 - 自旋失败阻塞
  - lock/synchronized
    - lock需要手动上锁解锁，synchronized自动
- GC
  - 标记-清楚，标记-复制，标记整理，分区分代GC

### 1.4 Golang

- 语法简单，无类无继承
  - 接口无序显式声明，通过结构体实现复用
- 使用goroutine协程
  - 一个线程：数千协程
  - 成本低，无系统级上下文切换
- 静态类型+垃圾回收
  - 三色标记法（并发），非分代回收，目标减少stw并提高吞吐
    - 白色未访问对象，GC回收
    - 灰色已被访问，但引用对象未完全被扫描
    - 黑色已访问且完全扫描，确定存活
  - 过程 - 触发上次GC的两倍
    - STW，根据根对象标记灰色
    - 并发标记 - 后台遍历灰色对象，将其引用对象标记为灰色，自身变黑
    - STW，确保所有对象被处理，剩余白色对象为可回收

### 1.5 Vue3

- 响应式编程
- TypeScript原生支持

### 1.6 Spring和Springboot

- AOP/IOC
- 工厂模式和单例模式
  - 工厂模式通过工程获取对象实例，实现创建和使用的解藕
  - 单例模式，保证一个类只有一个实例，提供全局访问节点

### 1.7 Docker

- 容器/虚拟机
- **Docker 如何实现资源隔离？底层技术是什么？**
  - 需要提到 Linux 的 Namespace（隔离进程、网络等）和 Cgroups（限制资源使用）。

- CI/CD

### 1.8 ML

- 分类/回归
- 分类
  - 监督学习：有标签
  - 无监督学习：无标签/数据本身就是标签

- 正则化 L1和Dropout都会可能导致过稀疏（欠拟合）
  - L1 lasso 在loss中增加 $\lamba \sum |w|$ 使部分权重趋近于0，实现特征选择和稀疏性
  - L2 ridge 在loss中增加 $\lamba \sum w^2$ 惩罚大权重
  - dropout 训练时关闭部分神经元，相当于训练子网络，最后传播相当于子网络平均和
- SVM
  - eg.异或 添加维度 $x_1^2 + x_2^2$
  - 核技巧 - 通过核函数隐式完成映射 - 高斯核（RBF）
- 常见激活函数
  - Relu
    - $f(x) = \max(0, x)$
  - Tanh
    - $\tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$
  - Sigmoid
    - $\sigma(x) = \frac{1}{1 + e^{-x}}$
  - Softmax
    - $\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}$

- 损失函数

  - 分类任务

  - |              名称              |                             公式                             |                        特点                        |   适用场景   |           注意事项           |
    | :----------------------------: | :----------------------------------------------------------: | :------------------------------------------------: | :----------: | :--------------------------: |
    | **交叉熵损失 (Cross Entropy)** |              $L = -\sum_{i=1}^n y_i \log(p_i)$               | - 衡量概率分布差异 - 适用于多分类（与Softmax配合） | 多分类输出层 |     需保证输出概率和为1      |
    |   **二元交叉熵 (Binary CE)**   | $L = -\frac{1}{n}\sum_{i=1}^n [y_i \log(p_i) + (1-y_i)\log(1-p_i)]$ |            - 二分类专用 - 与Sigmoid配合            | 二分类输出层 | 输出需通过Sigmoid压缩到(0,1) |

    回归任务

    |              名称              |                             公式                             |                            特点                             |          适用场景          |            注意事项             |
    | :----------------------------: | :----------------------------------------------------------: | :---------------------------------------------------------: | :------------------------: | :-----------------------------: |
    |       **均方误差 (MSE)**       |      $L = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$       |           - 对异常值敏感 - 梯度随误差增大线性增长           |   数值预测（如房价预测）   |          需数据标准化           |
    |     **平均绝对误差 (MAE)**     |                $ L = \frac{1}{n}\sum_{i=1}^n$                |                       y_i - \hat{y}_i                       |             $              | - 对异常值鲁棒 - 梯度恒定（±1） |
    |         **Huber损失**          |      $ L = \begin{cases} \frac{1}{2}(y - \hat{y})^2 & $      |                         y - \hat{y}                         |   \leq \delta \ \delta(    |           y - \hat{y}           |
    | **分位数损失 (Quantile Loss)** | $L = \sum_{i=1}^n \max(\tau(y_i - \hat{y}_i), (\tau-1)(y_i - \hat{y}_i))$ | - 预测指定分位数（如中位数） - *τ*控制分位点（0.5为中位数） | 不确定性估计（如金融预测） |        *τ*需根据需求设置        |



### 1.9 DL

- DL/ML
  - 多层神经网络自动学习特征，传统机器学习依赖人工特征
- $\sigma(wx+b)$
- CNN
  - Conv 提取局部特征
  - Pooling 降维
- RNN/LSTM/GRU
  - BPTT
    - 根据时间数据通路，链式求导
  - lstm
    - ![img](https://i.wolves.top/picgo/202503022240437.png)
- Transformer/RNN
  - $Attention = softMax(\frac{QK^T}{\sqrt{d_k}})V$ 每一层进行softmax
  - 分词器/one-hot
    - 单维扩展/扩展维度
  - 位置编码
    - 注意力不带位置信息，需要位置编码主动设置位置信息

## 2、项目

### 2.1 毕设

- 背景与设计
  - 医疗领域：症状、疾病、药品、治疗方案多维度关联

- 优化 - RAG 知识库检索系统
  - 知识变向量

### 2.2 个人博客

### 2.3 题库管理系统

- 为什么选EL-admin
  - 默认提供构造引擎，全县管理，集成了大量常用开发模块，可以快速开发后台
- 数据库设计
  - 用户
  - 题目表
- 权限控制
  - `PreAuthorize("hasRole('TEACHER')")`

### 2.4 多地温读检测系统

- 为什么使用头文件
  - 低耦合，高复用，减轻硬件学习成本
- Lnc/src
- Totp
  - 时间+密钥，HMAC-SHA1 = 20字节（160位）哈希值
    - 密钥填充到64字节，超过64字节就分块，先内部hash，再外部hash，拼接得到20位（取最终的h0-h4）
  - 取哈希值的**最后一个字节**的低 4 位（取值范围 0~15），作为偏移量（`offset`）。
  - 从哈希值的第 `offset` 字节开始，连续取 4 个字节（32 位），组成一个**整数**。
  - 对这个整数取模运算 （%1000000）

 ### 2.5 遥感

- RSPrompt
  - 通过SAM中间层提取多尺度信息，通过卷积减少规模
  - 基于锚点，类似于fastrcnn，生成候选区
  - 引用了transformer的query
- MMRotate-SAM
  - 先生成水平框（R-CNN）
  - 水平框作为mask传给sam
  - 最小外接矩形算法生成旋转框
- SAM
  - 基于 Vision Transformer (ViT)，将图像转换为高维特征。
  - 将用户提示（点、框、文本）编码为向量。
  - 结合图像和提示特征，生成分割掩码。
- Yolo v8
  - obb遥感优化
  - YOLOv5的耦合头（分类与回归共享特征）易导致任务冲突，影响密集目标检测。
  - 在遥感密集场景（如港口船舶检测）中，误检率（False Positive）降低10%-15%。
